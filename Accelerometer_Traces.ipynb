{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Directories/ Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import find_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:Users\\mathiopv\\OneDrive - Charité - Universitätsmedizin Berlin\\ENTRAINMENT_PROJECT\n"
     ]
    }
   ],
   "source": [
    "onedrive = find_folders.get_onedrive_path()\n",
    "project_path = find_folders.get_onedrive_path(\"entrainment\")\n",
    "print(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percept_ID</th>\n",
       "      <th>Blocks</th>\n",
       "      <th>Cond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sub005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sub005</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sub005</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sub005</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sub005</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sub005</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sub005</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sub006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sub006</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sub006</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Percept_ID  Blocks  Cond\n",
       "0     Sub005       1     1\n",
       "1     Sub005       2     1\n",
       "2     Sub005       3     2\n",
       "3     Sub005       4     2\n",
       "4     Sub005       5     3\n",
       "5     Sub005       6     3\n",
       "6     Sub005       7     4\n",
       "7     Sub006       1     1\n",
       "8     Sub006       2     1\n",
       "9     Sub006       3     1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accel_blocks_df = pd.read_excel(os.path.join(\n",
    "    project_path,\n",
    "    'results',\n",
    "    'accelerometer',\n",
    "    'Accel_Blocks.xlsx'\n",
    "))\n",
    "\n",
    "accel_blocks_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = 'S:\\\\AG\\\\AG-Bewegungsstoerungen-II\\\\LFP\\\\PROJECTS\\\\ENTRAINMENT\\\\Accelerometer\\\\retap_results\\\\features'\n",
    "blocks_path = 'S:\\\\AG\\\\AG-Bewegungsstoerungen-II\\\\LFP\\\\PROJECTS\\\\ENTRAINMENT\\\\Accelerometer\\\\retap_results\\\\extracted_tapblocks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features = ['freq', 'mean_raise_velocity', 'coefVar_raise_velocity', 'trace_RMSn', 'coefVar_intraTapInt', 'slope_intraTapInt','trace_entropy','jerkiness_trace', 'mean_tapRMS',\n",
    "                'coefVar_tapRMS', 'mean_impactRMS', 'coefVar_impactRMS', 'slope_impactRMS', 'coefVar_tap_entropy', 'slope_tap_entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub005\n",
      "Sub006\n",
      "Sub009\n",
      "Sub014\n",
      "Sub029\n",
      "Sub065\n",
      "Sub021\n",
      "Sub025\n",
      "Sub028\n",
      "Sub033\n",
      "Sub050\n"
     ]
    }
   ],
   "source": [
    "all_subs = accel_blocks_df['Percept_ID'].unique()\n",
    "\n",
    "for sub in all_subs:\n",
    "    print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in all_subs:\n",
    "\n",
    "    this_sub = sub\n",
    "\n",
    "    for cond in np.arange(1,5):\n",
    "\n",
    "        this_cond = cond\n",
    "\n",
    "        these_blocks = accel_blocks_df.loc[(accel_blocks_df['Percept_ID'] == this_sub) & (accel_blocks_df['Cond'] == this_cond), 'Blocks']\n",
    "        block_strings = ['block' + str(num) for num in these_blocks]\n",
    "        print(block_strings)\n",
    "\n",
    "        # Filter the json files based on conditions\n",
    "        jsons_to_import = []\n",
    "        for filename in os.listdir(features_path):\n",
    "            if filename.endswith('.json') and this_sub in filename:\n",
    "                for block_str in block_strings:\n",
    "                    if filename.endswith(f'{block_str}.json'):\n",
    "                        jsons_to_import.append(filename)\n",
    "\n",
    "        print(jsons_to_import)\n",
    "\n",
    "        # Filter the csv files based on conditions\n",
    "        csvs_to_import = []\n",
    "        for filename in os.listdir(blocks_path):\n",
    "            if filename.endswith('.csv') and this_sub in filename:\n",
    "                for block_str in block_strings:\n",
    "                    if filename.endswith(f'{block_str}_250Hz.csv'):\n",
    "                        csvs_to_import.append(filename)\n",
    "\n",
    "        print(csvs_to_import)\n",
    "\n",
    "        # Read the selected JSON files\n",
    "\n",
    "        combined_dict = []\n",
    "        for filename in jsons_to_import:\n",
    "            file_path = os.path.join(features_path, filename)\n",
    "            with open(file_path) as f:\n",
    "                this_block_feat = json.load(f)\n",
    "                matching_keys = set(imp_features) & set(this_block_feat.keys())\n",
    "                combined_dict.append({key: this_block_feat[key] for key in matching_keys})\n",
    "\n",
    "        #SAVE IT\n",
    "        suptitle = str(this_sub) + ' - Condition ' + str(this_cond)\n",
    "\n",
    "        file_name = \"\".join(suptitle.split()) + '_features.json'\n",
    "\n",
    "        # Combine the file name with the current directory to create the file path\n",
    "        file_path = os.path.join(\n",
    "            project_path,\n",
    "            'results',\n",
    "            'accelerometer',\n",
    "            'inspections')\n",
    "\n",
    "        # Serializing json\n",
    "        json_object = json.dumps(combined_dict, indent=4)\n",
    "        \n",
    "        # Writing to sample.json\n",
    "        with open(os.path.join(file_path,file_name), \"w\") as outfile:\n",
    "            outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig, axs = plt.subplots(len(csvs_to_import),1, figsize = (18,10))\n",
    "\n",
    "suptitle = str(this_sub) + ' - Condition ' + str(this_cond)\n",
    "fig.suptitle(suptitle, fontsize=14, fontweight='bold')\n",
    "\n",
    "rounded_list = [\n",
    "    {key: round(value, 2) for key, value in dictionary.items()}\n",
    "    for dictionary in combined_dict\n",
    "]\n",
    "\n",
    "for num, file in enumerate(csvs_to_import):\n",
    "    this_block_csv = pd.read_csv(os.path.join(blocks_path,file))\n",
    "    axs[num].plot(this_block_csv)\n",
    "    axs[num].set_ylabel('Acceleration [g] - ' + str(block_strings[num]))\n",
    "    axs[num].set_title(rounded_list[num])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(\n",
    "    project_path,\n",
    "    'results',\n",
    "    'accelerometer',\n",
    "    'inspections',\n",
    "    \"\".join(suptitle.split()),\n",
    "), dpi = 250\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average all blocks for each condition within subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathiopv\\AppData\\Local\\Temp\\ipykernel_15600\\3346489467.py:37: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_features_cond1 = all_features_cond1.append(averaged_values, ignore_index=True)\n",
      "C:\\Users\\mathiopv\\AppData\\Local\\Temp\\ipykernel_15600\\3346489467.py:37: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_features_cond1 = all_features_cond1.append(averaged_values, ignore_index=True)\n",
      "C:\\Users\\mathiopv\\AppData\\Local\\Temp\\ipykernel_15600\\3346489467.py:37: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_features_cond1 = all_features_cond1.append(averaged_values, ignore_index=True)\n",
      "C:\\Users\\mathiopv\\AppData\\Local\\Temp\\ipykernel_15600\\3346489467.py:37: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_features_cond1 = all_features_cond1.append(averaged_values, ignore_index=True)\n",
      "C:\\Users\\mathiopv\\AppData\\Local\\Temp\\ipykernel_15600\\3346489467.py:37: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_features_cond1 = all_features_cond1.append(averaged_values, ignore_index=True)\n",
      "C:\\Users\\mathiopv\\AppData\\Local\\Temp\\ipykernel_15600\\3346489467.py:37: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_features_cond1 = all_features_cond1.append(averaged_values, ignore_index=True)\n",
      "C:\\Users\\mathiopv\\AppData\\Local\\Temp\\ipykernel_15600\\3346489467.py:37: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_features_cond1 = all_features_cond1.append(averaged_values, ignore_index=True)\n",
      "C:\\Users\\mathiopv\\AppData\\Local\\Temp\\ipykernel_15600\\3346489467.py:37: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_features_cond1 = all_features_cond1.append(averaged_values, ignore_index=True)\n",
      "C:\\Users\\mathiopv\\AppData\\Local\\Temp\\ipykernel_15600\\3346489467.py:37: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_features_cond1 = all_features_cond1.append(averaged_values, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "json_dir = os.path.join(\n",
    "    project_path,\n",
    "    'results', 'accelerometer', 'inspections', 'Condition4'\n",
    ")\n",
    "all_features_cond1 = pd.DataFrame()\n",
    "\n",
    "# Loop through the JSON files in the directory\n",
    "for filename in os.listdir(json_dir):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(json_dir, filename)\n",
    "        percept_id = filename[:6]\n",
    "\n",
    "        # Load the JSON file\n",
    "        with open(file_path, 'r') as f:\n",
    "            json_data = json.load(f)\n",
    "        \n",
    "        # Initialize a dictionary to store the accumulated sums and counts for each key\n",
    "        summed_values = {}\n",
    "        count_values = {}\n",
    "        \n",
    "        # Iterate through the dictionaries in the JSON data\n",
    "        for data_dict in json_data:\n",
    "            # Accumulate the sums and counts for each key\n",
    "            for key, value in data_dict.items():\n",
    "                if key not in summed_values:\n",
    "                    summed_values[key] = value\n",
    "                    count_values[key] = 1\n",
    "                else:\n",
    "                    summed_values[key] += value\n",
    "                    count_values[key] += 1\n",
    "        \n",
    "        # Calculate the averages for each key\n",
    "        averaged_values = {key: summed_values[key] / count_values[key] for key in summed_values}\n",
    "        averaged_values['Percept_ID'] = percept_id\n",
    "        \n",
    "        # Append the averaged values to the dataframe\n",
    "        all_features_cond1 = all_features_cond1.append(averaged_values, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the resulting dataframe\n",
    "all_features_cond1 = all_features_cond1.reindex(columns=['Percept_ID'] + list(all_features_cond1.columns[:-1]))\n",
    "print(all_features_cond1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe as JSON\n",
    "json_file_path = os.path.join(json_dir, 'all_features_cond4.json')\n",
    "all_features_cond1.to_json(json_file_path, orient='records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all averaged values in three conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = os.path.join(\n",
    "    project_path,\n",
    "    'results', 'accelerometer', 'inspections\\\\'\n",
    ")\n",
    "\n",
    "feat_cond_1 = pd.read_json(str(json_dir) + 'all_features_cond1.json')\n",
    "feat_cond_2 = pd.read_json(str(json_dir) + 'all_features_cond2.json')\n",
    "feat_cond_4 = pd.read_json(str(json_dir) + 'all_features_cond4.json')\n",
    "\n",
    "feat_cond_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sub005' 'Sub006' 'Sub021' 'Sub025' 'Sub033' 'Sub050']\n"
     ]
    }
   ],
   "source": [
    "# Get the column values as NumPy arrays\n",
    "column1_values = feat_cond_1['Percept_ID'].values\n",
    "column2_values = feat_cond_2['Percept_ID'].values\n",
    "column3_values = feat_cond_4['Percept_ID'].values\n",
    "\n",
    "# Find the similar values between the three columns\n",
    "similar_values = np.intersect1d(column1_values, np.intersect1d(column2_values, column3_values))\n",
    "print(similar_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# Get the column names excluding 'Percept_ID'\n",
    "columns = [col for col in feat_cond_1.columns if col != 'Percept_ID']\n",
    "\n",
    "#fig, axes = plt.subplots(1, len(columns), figsize=(25, 5))  # Adjust figsize as needed\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "# Iterate over each column and create a boxplot for each dataframe\n",
    "for i, column in enumerate(columns):\n",
    "    # Get the data for the column from each dataframe\n",
    "    data1 = feat_cond_1[column]\n",
    "    data2 = feat_cond_2[column]\n",
    "    data3 = feat_cond_3[column]\n",
    "\n",
    "     # Create a boxplot for the column in the corresponding subplot\n",
    "    axes[i].boxplot([data1, data2, data3], showfliers=False)\n",
    "    axes[i].scatter([1]*len(data1), data1, color='red')\n",
    "    axes[i].scatter([2]*len(data2), data2, color='blue')\n",
    "    axes[i].scatter([3]*len(data3), data3, color='green')\n",
    "    axes[i].set_title(column)\n",
    "\n",
    "\n",
    "    # Create a boxplot for the column in the corresponding subplot\n",
    "    axes[i].boxplot([data1, data2, data3])\n",
    "    axes[i].set_title(column)\n",
    "\n",
    "# Add a legend at the bottom of the plot\n",
    "legend_labels = ['M1S0', 'M1S1:PreSubharmonic', 'M1S1:Subh-Highest Amp']\n",
    "legend_markers = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color) for color in ['red', 'blue', 'green']]\n",
    "fig.legend(legend_markers, legend_labels, loc='lower center', ncol=3)\n",
    "\n",
    "# Adjust spacing between subplots and legend\n",
    "fig.tight_layout(rect=[0, 0.1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(\n",
    "    json_dir, 'All_avg_features_conds'\n",
    "), dpi = 250\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare motor performance in patients with vs without subharmonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
