{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import public packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.patches import Rectangle\n",
    "import scipy\n",
    "import mne\n",
    "import sys\n",
    "\n",
    "from mne.time_frequency import tfr_morlet\n",
    "from mne.baseline import rescale\n",
    "from mne.stats import permutation_cluster_test\n",
    "from scipy.signal import spectrogram, hann, butter, filtfilt, hilbert\n",
    "from scipy import signal, interpolate, stats\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "from io import open\n",
    "from importlib import reload\n",
    "\n",
    "# import own functions\n",
    "from utils import find_folders\n",
    "import dat_preproc\n",
    "import fix_annot_onsets\n",
    "import mat2fif\n",
    "import baseline_correction\n",
    "import normalization\n",
    "import anal_functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Directories/ Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:Users\\mathiopv\\OneDrive - Charité - Universitätsmedizin Berlin\\ENTRAINMENT_PROJECT\n"
     ]
    }
   ],
   "source": [
    "reload(find_folders)\n",
    "onedrive = find_folders.get_onedrive_path()\n",
    "project_path = find_folders.get_onedrive_path(\"entrainment\")\n",
    "print(project_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Peaks and Plot Analytic Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load raw fif data\n",
    "\n",
    "test_raw = mne.io.read_raw_fif(os.path.join(\n",
    "    project_path,\n",
    "        'data',\n",
    "        'Fifs',\n",
    "        'without_med_FTG',\n",
    "        'Sub050_ARTREJECT_FIF.fif'\n",
    "    )\n",
    ")\n",
    "\n",
    "subID = 'Sub050'\n",
    "fft_name = str(subID) + '_'\n",
    "print(fft_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(dat_preproc)\n",
    "x = test_raw.get_data() \n",
    "x1 = x[0,:]\n",
    "\n",
    "#peakMed = 80\n",
    "peakStim = 63\n",
    "\n",
    "#dat_ngam = dat_preproc.low_highpass_filter(x1, peakMed-2, peakMed+2) \n",
    "dat_subh = dat_preproc.low_highpass_filter(x1, peakStim-2, peakStim+2) \n",
    "#dat_inb = dat_preproc.low_highpass_filter(x1, peakStim+3, peakMed-3) \n",
    "\n",
    "#datall = [dat_ngam, dat_subh, dat_inb] \n",
    "#labels = ['Peak'+str(peakMed)+'Hz','Peak'+str(peakStim)+'Hz', str(peakStim+3) + '-' + str(peakMed-3)+'Hz']\n",
    "\n",
    "datall = [dat_subh] \n",
    "labels = ['Peak'+str(peakStim)+'Hz']\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_rms(a, window_size):\n",
    "  a2 = np.power(a,2)\n",
    "  window = np.ones(window_size)/float(window_size)\n",
    "  return np.sqrt(np.convolve(a2, window, 'valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "sm_signal_np = np.empty(shape = (1, x1.shape[0] - 499))\n",
    "sm_signal_np[:] = np.nan\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(12, 5))\n",
    "wintosmooth = 500\n",
    "\n",
    "for idx, dat in enumerate(datall):\n",
    "    hiltr = hilbert(dat)\n",
    "    amplitude_envelope = np.abs(hiltr)\n",
    "    zscore_sign = stats.zscore(np.squeeze(amplitude_envelope))\n",
    "\n",
    "    sm_signal = window_rms(zscore_sign, wintosmooth)\n",
    "    \n",
    "    plt.plot(sm_signal, label = labels[idx])\n",
    "    #plt.plot(np.arange(0,75000), amplitude_envelope, label = labels[idx]) \n",
    "    \n",
    "    #axes[idx].axvline(26250, color = 'b', ls='--', lw=2, label = 'Stim On')\n",
    "    #axes[idx].axvline(50250, color = 'g', ls='--', lw=2, label = 'Stim Off')\n",
    "    plt.ylabel('Analytic Signal')\n",
    "    plt.xlim([0, sm_signal.shape[0]])\n",
    "\n",
    "    \n",
    "    sm_signal_np[idx,:] = sm_signal\n",
    "\n",
    "    #axes[idx].set_xticks(ticks = np.arange(0, 80000, 10000), labels = np.arange(0,320,40))\n",
    "    plt.xlabel('Time [sec]')\n",
    "\n",
    "    \n",
    "\n",
    "plt.suptitle('Smoothing Window: 500 samples')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x[4, :] \n",
    "sm_stim = window_rms(x2, wintosmooth)\n",
    "sm_stim1 = (sm_stim)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize = (18,6))\n",
    "#plt.rcParams['font.size'] = 10\n",
    "ax2 = ax1.twinx()\n",
    "for idx, dat in enumerate(sm_signal_np):\n",
    "    ax1.plot(sm_signal_np[idx,:], label = labels[idx], lw = 2)\n",
    "ax2.plot(sm_stim1[:], label = 'Stimulation', color = 'grey', ls='--', lw=3, alpha = 0.4)\n",
    "ax1.legend()\n",
    "ax1.set_ylabel('Z-scored Smoothed Analytic Signal')\n",
    "ax2.set_ylabel('Stimulation Amplitude [mA]')\n",
    "#ax2.set_yticks(np.arange(0.5, 2.5, 0.25))\n",
    "#ax2.set_yticklabels(np.arange(0.25, 2.25, 0.25))\n",
    "#ax1.set_xlim(0, sm_signal_np.shape[0])\n",
    "#ax1.set_xticks(np.arange(0, 100000, 20000))\n",
    "#ax1.set_xticklabels(np.arange(0, 400, 80))\n",
    "ax1.set_xlabel('Time [samples]')\n",
    "plt.title(str(subID))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm_analSignal = np.transpose(np.squeeze(np.array([[sm_signal_np[0]], [sm_signal_np[1]],[sm_signal_np[2]],[sm_stim1]])))\n",
    "sm_analSignal = np.transpose(np.squeeze(np.array([[sm_signal_np[0]],[sm_stim1]])))\n",
    "sm_analSignal_df = pd.DataFrame(sm_analSignal, \n",
    "    columns = ['StimOn','StimVec'],\n",
    "    )\n",
    "print(sm_analSignal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_fig = os.path.join(project_path, 'figures','anal_signal','without_med_FTG/')\n",
    "fft_file = os.path.join(project_path, 'data','anal_signal','without_med_FTG/')\n",
    "\n",
    "plt.savefig(str(fft_fig)+str(fft_name)+'sm_analSignal',dpi = 300)\n",
    "sm_analSignal_df.to_csv(str(fft_file)+str(fft_name)+'sm_analSignal.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Analytic Signal to Epochs of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert analytic signal arrays to mne objects:\n",
    "anal_signal_df = pd.read_csv(os.path.join(\n",
    "    project_path,\n",
    "    'data',\n",
    "    'anal_signal',\n",
    "    'without_med_FTG',\n",
    "    'Sub050_sm_analSignal.csv'\n",
    "))\n",
    "\n",
    "df_filtered = anal_signal_df.iloc[:, 1:]\n",
    "dat_anal = df_filtered.values\n",
    "ch_names = list(df_filtered.columns)\n",
    "sfreq = 250\n",
    "info = mne.create_info(ch_names, sfreq)\n",
    "raw_anal = mne.io.RawArray(dat_anal.T, info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fif_name = os.path.join(project_path, 'data','anal_signal','without_med_FTG','Sub050'+'_AnalFIF.fif')\n",
    "print(fif_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_anal.save(fif_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anal_epochs = pd.read_excel(os.path.join(\n",
    "    project_path,\n",
    "    'data', 'anal_signal',\n",
    "    'Anal_epochs.xlsx'\n",
    "))\n",
    "\n",
    "anal_epochs\n",
    "#subID = 'Sub005'\n",
    "#fft_name = str(subID) + '_'\n",
    "#print(fft_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:Users\\mathiopv\\OneDrive - Charité - Universitätsmedizin Berlin\\ENTRAINMENT_PROJECT\\data\\anal_signal\\with_med_FTG\\Sub065_AnalFIF.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 113200 =      0.000 ...   452.800 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathiopv\\AppData\\Local\\Temp\\ipykernel_15264\\3838563601.py:4: RuntimeWarning: This filename (C:Users\\mathiopv\\OneDrive - Charité - Universitätsmedizin Berlin\\ENTRAINMENT_PROJECT\\data\\anal_signal\\with_med_FTG\\Sub065_AnalFIF.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  anal_fif = mne.io.read_raw_fif(os.path.join(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"cropped_anal_1tp = anal_functions.anal_transitions_1tp(anal_epochs, anal_fif, subID, 20) \\n\\nnp.save(str(anal_file) + str(subID)+'sm_analSignal1TP.npy', cropped_anal_1tp)\\nplt.savefig(str(anal_fig) + str(subID)+'sm_analSignal2TP',dpi = 150)\""
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "'''anal_file = os.path.join(project_path, 'data','anal_signal', 'with_med_FTG/')\n",
    "anal_file = os.path.join(project_path, 'data','anal_signal', 'with_med_FTG/')'''\n",
    "\n",
    "anal_fif = mne.io.read_raw_fif(os.path.join(\n",
    "    project_path,\n",
    "        'data',\n",
    "        'anal_signal',\n",
    "        'with_med_FTG',\n",
    "        'Sub065_AnalFIF.fif'\n",
    "    )\n",
    ")\n",
    "\n",
    "subID = 'Sub007'\n",
    "%matplotlib qt\n",
    "anal_fif.plot(duration = 200)\n",
    "'''cropped_anal_1tp = anal_functions.anal_transitions_1tp(anal_epochs, anal_fif, subID, 20) \n",
    "\n",
    "np.save(str(anal_file) + str(subID)+'sm_analSignal1TP.npy', cropped_anal_1tp)\n",
    "plt.savefig(str(anal_fig) + str(subID)+'sm_analSignal2TP',dpi = 150)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "anal_file = os.path.join(project_path, 'data','anal_signal', 'SWITCH_OFF/')\n",
    "anal_fig = os.path.join(project_path, 'figures','anal_signal', 'with_med_FTG/')\n",
    "\n",
    "\n",
    "directory = os.path.join(project_path,\n",
    "                         'data',\n",
    "                         'anal_signal',\n",
    "                         'with_med_FTG')  # Update with your directory path\n",
    "\n",
    "# Create a file pattern to match .fif files\n",
    "file_pattern = '*.fif'\n",
    "\n",
    "# Get a list of file paths that match the pattern\n",
    "file_list = glob.glob(os.path.join(directory, file_pattern))\n",
    "\n",
    "# Loop through the file list\n",
    "for file_path in file_list:\n",
    "    \n",
    "    file_name = os.path.basename(file_path)\n",
    "    subID = file_name[:6]\n",
    "\n",
    "    anal_fif = mne.io.read_raw_fif(file_path)\n",
    "\n",
    "    cropped_anal_1tp = anal_functions.anal_transitions_1tp(anal_epochs, anal_fif, subID, 10)\n",
    "\n",
    "    np.save(str(anal_file) + str(subID)+'sm_analSignalSWITCH_OFF.npy', cropped_anal_1tp)\n",
    "    plt.savefig(str(anal_fig) + str(subID)+'sm_analSignalSWITCH_OFF',dpi = 150)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(anal_functions)\n",
    "cropped_anal_2tp = anal_functions.anal_transitions_2tp(anal_epochs, anal_fif, subID, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anal_fig = os.path.join(project_path, 'figures','anal_signal', 'with_med_FTG/')\n",
    "anal_file = os.path.join(project_path, 'data','anal_signal', 'with_med_FTG/')\n",
    "\n",
    "plt.savefig(str(anal_fig) + str(subID)+'sm_analSignal2TP',dpi = 150)\n",
    "np.save(str(anal_file) + str(subID)+'sm_analSignal2TP.npy', cropped_anal_2tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(anal_functions)\n",
    "cropped_anal_1tp = anal_functions.anal_transitions_1tp(anal_epochs, anal_fif, subID, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.savefig(str(anal_fig) + str(subID)+'sm_analSignal1TP',dpi = 150)\n",
    "anal_file = os.path.join(project_path, 'data','anal_signal', 'with_med_FTG/')\n",
    "np.save(str(anal_file) + str(subID)+'sm_analSignal1TP.npy', cropped_anal_1tp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Cropped Analytic Signal and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory path\n",
    "directory = os.path.join(project_path, 'data', 'anal_signal')\n",
    "\n",
    "# Find all .npy files in the directory ending with 'analSignal2TP.npy'\n",
    "file_list = [file for file in os.listdir(directory) if file.endswith('SWITCH_OFF.npy')]\n",
    "\n",
    "# Create an empty list to store the data arrays\n",
    "data_list = []\n",
    "\n",
    "# Loop through the file list and load the data\n",
    "for file in file_list:\n",
    "    data = np.load(os.path.join(directory, file))\n",
    "\n",
    "    if data.shape[0] == 4:\n",
    "        my_vec = 1\n",
    "    else:\n",
    "        my_vec = 0\n",
    "\n",
    "    data_list.append(data[my_vec,:])  # Select the first 10000 columns\n",
    "\n",
    "# Stack the data arrays along the third axis\n",
    "stacked_data = np.stack(data_list, axis=0)\n",
    "\n",
    "# Calculate the mean and standard error over the 3rd dimension\n",
    "mean_data = np.mean(stacked_data, axis=0)\n",
    "sem_data = np.std(stacked_data, axis=0) / np.sqrt(stacked_data.shape[0])\n",
    "\n",
    "plt.plot(np.arange(1,5002), mean_data, label='Subharmonic')\n",
    "plt.fill_between(np.arange(1,5002),mean_data - sem_data, mean_data + sem_data, alpha=0.3)\n",
    "\n",
    "plt.axvline(x=2500, color='grey', linestyle='--', lw = 3, alpha = 0.4, label = 'Stim Off')\n",
    "\n",
    "plt.xlim(0,5000)\n",
    "plt.xticks(np.arange(0,5500,500), labels=np.arange(-10,12,2))\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Z-scored Smoothed Analytic Signal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(mean_data.shape[0]) + 1  # Adjusted to start from 1\n",
    "\n",
    "labels = ['Spontaneous FTG', 'Stim-induced FTG', 'In-Between Activity']\n",
    "\n",
    "for i in range(mean_data.shape[0]):\n",
    "    plt.plot(x, mean_data[i], label=labels[i])\n",
    "\n",
    "for i in range(mean_data.shape[0]):\n",
    "    plt.fill_between(x, mean_data[i] - sem_data[i], mean_data[i] + sem_data[i], alpha=0.3)\n",
    "\n",
    "plt.axvline(x=5000, color='grey', linestyle='--', lw = 3, alpha = 0.4, label = 'Subharmonic On')\n",
    "\n",
    "plt.xlim(0,10000)\n",
    "plt.xticks(np.arange(0,10500,1000), labels=np.arange(-20,24,4))\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Z-scored Smoothed Analytic Signal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_fig = os.path.join(project_path, 'figures', 'anal_signal\\\\')\n",
    "\n",
    "plt.savefig(str(fft_fig)+'AVG_AnalCropped_SWITCH_OFF',dpi = 300)\n",
    "plt.savefig(str(fft_fig)+'AVG_AnalCropped_SWITCH_OFF.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = 0.05  # arbitrary\n",
    "dfn = 2 - 1  # degrees of freedom numerator\n",
    "dfd = med_anal.shape[0] - 2  # degrees of freedom denominator\n",
    "thresh = scipy.stats.f.ppf(1 - pval, dfn=dfn, dfd=dfd)  # F distribution\n",
    "print(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_nd = np.empty([6,med_anal.shape[0]])\n",
    "perm_nd[:] = np.nan\n",
    "perm_nd[0,:] = np.transpose(med_anal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.expand_dims(med_anal, axis = 2)\n",
    "y1 = np.expand_dims(stim_anal, axis = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H0 = np.empty([1000,6])\n",
    "T_obs, clusters, cluster_p_values, H0 = \\\n",
    "    permutation_cluster_test([y, y1], n_permutations=1000,\n",
    "                             threshold=None, n_jobs=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_p_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make all Signals same Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anal_epochs = pd.read_excel(os.path.join(\n",
    "    project_path,\n",
    "    'data', 'anal_signal',\n",
    "    'Anal_epochs.xlsx'\n",
    "))\n",
    "\n",
    "anal_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "directory = os.path.join(project_path,\n",
    "                         'data',\n",
    "                         'anal_signal',\n",
    "                         'with_med_FTG//')  # Update with your directory path\n",
    "\n",
    "# Create a file pattern to match .fif files\n",
    "file_pattern = '*.fif'\n",
    "\n",
    "# Get a list of file paths that match the pattern\n",
    "file_list = glob.glob(os.path.join(directory, file_pattern))\n",
    "\n",
    "# Loop through the file list\n",
    "for file_path in file_list:\n",
    "    \n",
    "    file_name = os.path.basename(file_path)\n",
    "    subID = file_name[:6]\n",
    "\n",
    "    anal_fif = mne.io.read_raw_fif(file_path)\n",
    "\n",
    "    filtered_df = anal_epochs[anal_epochs['Percept_ID'] == subID]\n",
    "    \n",
    "    rec_on = 1\n",
    "    stim_on = filtered_df['Stim_On'].values[0]\n",
    "    subh_on = filtered_df['Subh_On'].values[0]\n",
    "    stim_off = filtered_df['Switch_Off'].values[0]\n",
    "    rec_off = anal_fif.times[-1]\n",
    "\n",
    "    part1 = anal_fif.copy().crop(tmin=rec_on, tmax = stim_on).get_data()\n",
    "    part2 = anal_fif.copy().crop(tmin=stim_on, tmax = subh_on).get_data()\n",
    "    part3 = anal_fif.copy().crop(tmin=subh_on, tmax = stim_off).get_data()\n",
    "    part4 = anal_fif.copy().crop(tmin=stim_off, tmax = rec_off).get_data()\n",
    "\n",
    "''''np.save(f'{directory}{subID}-Anal_Part1.npy', part1)\n",
    "    np.save(f'{directory}{subID}-Anal_Part2.npy', part2)\n",
    "    np.save(f'{directory}{subID}-Anal_Part3.npy', part3)\n",
    "    np.save(f'{directory}{subID}-Anal_Part4.npy', part4)'''\n",
    "'''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized Array 1: [[1.25052142 1.25218332 1.25378287 ... 1.2800318  1.28133285 1.28259325]\n",
      " [1.28381217 1.28498924 1.28612363 ... 2.1498909  2.15264153 2.15526128]\n",
      " [2.15774441 2.16008639 2.16228271 ... 0.63537651 0.63659191 0.63785678]\n",
      " [0.63917309 0.6405431  0.64196897 ... 0.64495903 0.64472431 0.64449739]]\n",
      "Resized Array 2: [[1.84965765 1.84990466 1.84984553 ... 1.14354157 1.14246857 1.14152467]\n",
      " [1.14071608 1.14004862 1.1395278  ... 0.74434274 0.74416059 0.74405468]\n",
      " [0.74402517 0.74407196 0.74419421 ... 0.61873412 0.61935055 0.62003797]\n",
      " [0.62079698 0.62162435 0.62251347 ... 0.64534938 0.64543706 0.645504  ]]\n",
      "Resized Array 3: [[1.67163801 1.67102385 1.67045951 ... 1.61311328 1.61333692 1.61354721]\n",
      " [1.61374104 1.61391652 1.61407316 ... 1.03388286 1.03494418 1.03610945]\n",
      " [1.03737354 1.03872991 1.04017079 ... 1.16402245 1.16626012 1.168468  ]\n",
      " [1.17063558 1.17275262 1.17480922 ... 0.79916251 0.79932612 0.79947239]]\n",
      "Resized Array 4: [[0.9150902  0.91125357 0.90743232 ... 0.78260773 0.77966678 0.77662849]\n",
      " [0.77349794 0.77028084 0.76698321 ... 0.66719097 0.66856748 0.67000866]\n",
      " [0.67148077 0.67295188 0.67439222 ... 0.76624715 0.7672655  0.76823437]\n",
      " [0.76915741 0.77003932 0.77088583 ... 0.67128104 0.6716786  0.67206365]]\n",
      "Resized Array 5: [[1.01423132 1.01671612 1.01916075 ... 1.3611095  1.36066532 1.36023319]\n",
      " [1.35981524 1.3594141  1.35903227 ... 0.67070258 0.6693688  0.66808355]\n",
      " [0.6668492  0.66566664 0.66453582 ... 0.78530204 0.78541207 0.78569192]\n",
      " [0.78619099 0.7869553  0.78802341 ... 0.         0.         0.        ]]\n",
      "Resized Array 6: [[1.66505301 1.66564369 1.66616654 ... 0.94925731 0.94917369 0.94909573]\n",
      " [0.94902408 0.94895899 0.94890076 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.83559257 0.83643377 0.83729041]\n",
      " [0.83816338 0.83905303 0.83996004 ... 0.680224   0.68184626 0.68345064]]\n",
      "Resized Array 7: [[1.44418585 1.4441818  1.4441272  ... 1.08527589 1.08479297 1.08441961]\n",
      " [1.08415329 1.08399045 1.08392704 ... 1.37191117 1.37238944 1.37277937]\n",
      " [1.37308705 1.37331891 1.37348199 ... 1.06292951 1.06339109 1.06374419]\n",
      " [1.0639863  1.06411529 1.06413043 ... 1.13486481 1.13390827 1.13298774]]\n",
      "Resized Array 8: [[0.71693045 0.71693724 0.7169891  ... 0.73846644 0.73683184 0.7351467 ]\n",
      " [0.73342025 0.73166257 0.72988451 ... 0.96527797 0.96599829 0.96680391]\n",
      " [0.96769989 0.96869087 0.9697817  ... 1.22288895 1.22326195 1.22366631]\n",
      " [1.22409964 1.22455943 1.22504354 ... 1.77534473 1.77418697 1.77300119]]\n"
     ]
    }
   ],
   "source": [
    "### resample with traces\n",
    "import traces\n",
    "\n",
    "# Specify the directory path\n",
    "directory = os.path.join(\n",
    "    project_path,\n",
    "    'data', 'anal_signal', 'with_med_FTG'\n",
    ")\n",
    "\n",
    "# Find all files in the directory ending with 'Anal_Part1.npy'\n",
    "file_list = [file for file in os.listdir(directory) if file.endswith('Anal_Part1.npy')]\n",
    "\n",
    "# Create an empty list to store the arrays\n",
    "arrays = []\n",
    "\n",
    "# Loop through the file list and load the arrays\n",
    "for file in file_list:\n",
    "    array = np.load(os.path.join(directory, file))\n",
    "    arrays.append(array)\n",
    "\n",
    "\n",
    "# Create a new list to store the resized arrays\n",
    "resized_arrays = []\n",
    "\n",
    "# Resize each array to the maximum length\n",
    "for arr in arrays:\n",
    "    resized_arr = np.resize(arr, (4, 50*250))\n",
    "    resized_arrays.append(resized_arr)\n",
    "\n",
    "# Print the resized arrays\n",
    "for i, arr in enumerate(resized_arrays):\n",
    "    print(f\"Resized Array {i+1}:\", arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 31555)\n",
      "(4, 32033)\n",
      "(4, 30935)\n",
      "(4, 39273)\n",
      "(4, 13582)\n",
      "(4, 7998)\n",
      "(4, 25273)\n",
      "(4, 58252)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt \n",
    "\n",
    "f, axes = plt.subplots(nrows=2, ncols=4)\n",
    "\n",
    "for i, file in enumerate(file_list):\n",
    "    array = np.load(os.path.join(directory, file))\n",
    "    print(array.shape)\n",
    "    ax = axes.flat[i]\n",
    "    ax.plot(array[1,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 58252)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60*250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 12500)\n",
      "(4, 12500)\n",
      "(4, 12500)\n",
      "(4, 12500)\n",
      "(4, 12500)\n",
      "(4, 12500)\n",
      "(4, 12500)\n",
      "(4, 12500)\n"
     ]
    }
   ],
   "source": [
    "f, axes = plt.subplots(nrows=2, ncols=4)\n",
    "\n",
    "for i, arr in enumerate(resized_arrays):\n",
    "    print(arr.shape)\n",
    "    ax = axes.flat[i]\n",
    "    ax.plot(arr[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\n",
    "    project_path,\n",
    "    'data',\n",
    "    'anal_signal',\n",
    "    'Part4_Resized.npy'),resized_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 2 is out of bounds for array of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20128\\2926697554.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     'Part1_Resized.npy'))\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Stack the data arrays along the third axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mstacked_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpart1_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Calculate the mean and standard error over the 3rd dimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mathiopv\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_axis_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_ndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[0msl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 2 is out of bounds for array of dimension 2"
     ]
    }
   ],
   "source": [
    "'''file_list = [file for file in os.listdir(directory) if file.endswith('SWITCH_OFF.npy')]\n",
    "\n",
    "# Create an empty list to store the data arrays\n",
    "data_list = []\n",
    "\n",
    "# Loop through the file list and load the data\n",
    "for file in file_list:\n",
    "    data = np.load(os.path.join(directory, file))\n",
    "\n",
    "    if data.shape[0] == 4:\n",
    "        my_vec = 1\n",
    "    else:\n",
    "        my_vec = 0\n",
    "\n",
    "    data_list.append(data[my_vec,:])  # Select the first 10000 columns\n",
    "'''\n",
    "\n",
    "part1_list = np.load(os.path.join(\n",
    "    project_path,\n",
    "    'data',\n",
    "    'anal_signal',\n",
    "    'Part1_Resized.npy'))\n",
    "\n",
    "# Stack the data arrays along the third axis\n",
    "stacked_data = np.stack(part1_list, axis=0)\n",
    "\n",
    "# Calculate the mean and standard error over the 3rd dimension\n",
    "mean_data = np.mean(stacked_data, axis=0)\n",
    "sem_data = np.std(stacked_data, axis=0) / np.sqrt(stacked_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22500"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x29c81ee7fd0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(np.arange(0,len(mean_data)),mean_data)\n",
    "plt.fill_between(np.arange(0,len(mean_data)),mean_data - sem_data, mean_data + sem_data, alpha=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switching Stim Off Analytic Signal for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_anal = []\n",
    "\n",
    "ps_path = os.path.join(\n",
    "   project_path,\n",
    "   'data', 'anal_signal', 'switch_off'\n",
    ")\n",
    "\n",
    "for filename in os.listdir(ps_path):\n",
    "   if filename.endswith('SWITCH_OFF.csv'):\n",
    "   #with open(os.path.join(ps_path, filename), 'r') as f: # open in readonly mode\n",
    "      this_df = pd.read_csv(os.path.join(ps_path,filename))\n",
    "      this_stim_anal = this_df['StimOn']\n",
    "\n",
    "      stim_anal.append(this_stim_anal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stim_anal_df = pd.DataFrame(stim_anal)\n",
    "\n",
    "mean_values = all_stim_anal_df.mean(skipna=True)\n",
    "sem_values =  all_stim_anal_df.sem(skipna=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the mean with shaded area for \n",
    "plot_mean = mean_values[:]\n",
    "plot_sem = sem_values[:]\n",
    "plt.plot(plot_mean, color='blue', label = 'Stim-Induced FTG')\n",
    "plt.fill_between(plot_mean.index, plot_mean - plot_sem, plot_mean + plot_sem, color='lightblue')\n",
    "plt.axvline(x = 5000, color = 'grey', ls='--', lw=3, alpha = 0.4, label = 'Stim Off')\n",
    "plt.ylim(0.5,2)\n",
    "plt.xlim(2500,7500)\n",
    "plt.xticks(np.arange(2500,8000,500), labels=np.arange(-10,12,2))\n",
    "plt.legend()\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Z-scored Smoothed Analytic Signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_fig = os.path.join(project_path, 'results\\\\')\n",
    "\n",
    "plt.savefig(str(fft_fig)+'SWITCH_STIM_OFF',dpi = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
