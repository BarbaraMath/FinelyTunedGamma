{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import public packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.patches import Rectangle\n",
    "import scipy\n",
    "import mne\n",
    "import sys\n",
    "\n",
    "from mne.time_frequency import tfr_morlet\n",
    "from mne.baseline import rescale\n",
    "from mne.stats import permutation_cluster_test\n",
    "from scipy.signal import spectrogram, hann, butter, filtfilt, hilbert\n",
    "from scipy import signal, interpolate, stats\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "from io import open\n",
    "from importlib import reload\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "\n",
    "# import own functions\n",
    "from utils import find_folders\n",
    "import dat_preproc\n",
    "import fix_annot_onsets\n",
    "import mat2fif\n",
    "import baseline_correction\n",
    "import normalization\n",
    "import anal_functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Directories/ Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(find_folders)\n",
    "onedrive = find_folders.get_onedrive_path()\n",
    "project_path = find_folders.get_onedrive_path(\"entrainment\")\n",
    "print(project_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Peaks and Plot Analytic Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load raw fif data\n",
    "\n",
    "test_raw = mne.io.read_raw_fif(os.path.join(\n",
    "    project_path,\n",
    "        'data',\n",
    "        'Fifs',\n",
    "        'with_med_FTG',\n",
    "        'Sub005_FIF.fif'\n",
    "    )\n",
    ")\n",
    "\n",
    "subID = 'Sub005'\n",
    "fft_name = str(subID) + '_'\n",
    "print(fft_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(dat_preproc)\n",
    "x = test_raw.get_data() \n",
    "x1 = x[1,:]\n",
    "\n",
    "peakMed = 77\n",
    "peakStim = 65\n",
    "\n",
    "dat_ngam = dat_preproc.low_highpass_filter(x1, peakMed-2, peakMed+2) \n",
    "dat_subh = dat_preproc.low_highpass_filter(x1, peakStim-2, peakStim+2) \n",
    "#dat_inb = dat_preproc.low_highpass_filter(x1, peakStim+3, peakMed-3) \n",
    "\n",
    "#datall = [dat_ngam, dat_subh, dat_inb] \n",
    "#labels = ['Peak'+str(peakMed)+'Hz','Peak'+str(peakStim)+'Hz', str(peakStim+3) + '-' + str(peakMed-3)+'Hz']\n",
    "\n",
    "datall = [dat_ngam, dat_subh] \n",
    "labels = ['Peak'+str(peakStim)+'Hz']\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_subh.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "plt.plot(np.arange(0,dat_subh.shape[0]), dat_ngam)\n",
    "plt.plot(np.arange(0,dat_subh.shape[0]), x[5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_rms(a, window_size):\n",
    "  a2 = np.power(a,2)\n",
    "  window = np.ones(window_size)/float(window_size)\n",
    "  return np.sqrt(np.convolve(a2, window, 'valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "sm_signal_np = np.empty(shape = (1, x1.shape[0] - 499))\n",
    "sm_signal_np[:] = np.nan\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(12, 5))\n",
    "wintosmooth = 500\n",
    "\n",
    "for idx, dat in enumerate(datall):\n",
    "    hiltr = hilbert(dat)\n",
    "    amplitude_envelope = np.abs(hiltr)\n",
    "    zscore_sign = stats.zscore(np.squeeze(amplitude_envelope))\n",
    "\n",
    "    sm_signal = window_rms(zscore_sign, wintosmooth)\n",
    "    \n",
    "    plt.plot(sm_signal, label = labels[idx])\n",
    "    #plt.plot(np.arange(0,75000), amplitude_envelope, label = labels[idx]) \n",
    "    \n",
    "    #axes[idx].axvline(26250, color = 'b', ls='--', lw=2, label = 'Stim On')\n",
    "    #axes[idx].axvline(50250, color = 'g', ls='--', lw=2, label = 'Stim Off')\n",
    "    plt.ylabel('Analytic Signal')\n",
    "    plt.xlim([0, sm_signal.shape[0]])\n",
    "\n",
    "    \n",
    "    sm_signal_np[idx,:] = sm_signal\n",
    "\n",
    "    #axes[idx].set_xticks(ticks = np.arange(0, 80000, 10000), labels = np.arange(0,320,40))\n",
    "    plt.xlabel('Time [sec]')\n",
    "\n",
    "    \n",
    "\n",
    "plt.suptitle('Smoothing Window: 500 samples')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x[4, :] \n",
    "sm_stim = window_rms(x2, wintosmooth)\n",
    "sm_stim1 = (sm_stim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize = (18,6))\n",
    "#plt.rcParams['font.size'] = 10\n",
    "ax2 = ax1.twinx()\n",
    "for idx, dat in enumerate(sm_signal_np):\n",
    "    ax1.plot(sm_signal_np[idx,:], label = labels[idx], lw = 2)\n",
    "ax2.plot(sm_stim1[:], label = 'Stimulation', color = 'grey', ls='--', lw=3, alpha = 0.4)\n",
    "ax1.legend()\n",
    "ax1.set_ylabel('Z-scored Smoothed Analytic Signal')\n",
    "ax2.set_ylabel('Stimulation Amplitude [mA]')\n",
    "#ax2.set_yticks(np.arange(0.5, 2.5, 0.25))\n",
    "#ax2.set_yticklabels(np.arange(0.25, 2.25, 0.25))\n",
    "#ax1.set_xlim(0, sm_signal_np.shape[0])\n",
    "#ax1.set_xticks(np.arange(0, 100000, 20000))\n",
    "#ax1.set_xticklabels(np.arange(0, 400, 80))\n",
    "ax1.set_xlabel('Time [samples]')\n",
    "plt.title(str(subID))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm_analSignal = np.transpose(np.squeeze(np.array([[sm_signal_np[0]], [sm_signal_np[1]],[sm_signal_np[2]],[sm_stim1]])))\n",
    "sm_analSignal = np.transpose(np.squeeze(np.array([[sm_signal_np[0]],[sm_stim1]])))\n",
    "sm_analSignal_df = pd.DataFrame(sm_analSignal, \n",
    "    columns = ['StimOn','StimVec'],\n",
    "    )\n",
    "print(sm_analSignal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_fig = os.path.join(project_path, 'figures','anal_signal','without_med_FTG/')\n",
    "fft_file = os.path.join(project_path, 'data','anal_signal','without_med_FTG/')\n",
    "\n",
    "plt.savefig(str(fft_fig)+str(fft_name)+'sm_analSignal',dpi = 300)\n",
    "sm_analSignal_df.to_csv(str(fft_file)+str(fft_name)+'sm_analSignal.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Analytic Signal to Epochs of Interest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the analytic signal files to .fif objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert analytic signal arrays to mne objects:\n",
    "anal_signal_df = pd.read_csv(os.path.join(\n",
    "    project_path,\n",
    "    'data',\n",
    "    'anal_signal',\n",
    "    'without_med_FTG',\n",
    "    'Sub007_sm_analSignal.csv'\n",
    "))\n",
    "\n",
    "df_filtered = anal_signal_df.iloc[:, 1:]\n",
    "dat_anal = df_filtered.values\n",
    "ch_names = list(df_filtered.columns)\n",
    "sfreq = 250\n",
    "info = mne.create_info(ch_names, sfreq)\n",
    "raw_anal = mne.io.RawArray(dat_anal.T, info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fif_name = os.path.join(project_path, 'data','anal_signal','without_med_FTG','Sub007'+'_AnalFIF.fif')\n",
    "print(fif_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_anal.save(fif_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anal_epochs = pd.read_excel(os.path.join(\n",
    "    project_path,\n",
    "    'data', 'anal_signal',\n",
    "    'Anal_epochs.xlsx'\n",
    "))\n",
    "\n",
    "anal_epochs\n",
    "#subID = 'Sub005'\n",
    "#fft_name = str(subID) + '_'\n",
    "#print(fft_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''anal_file = os.path.join(project_path, 'data','anal_signal', 'with_med_FTG/')\n",
    "anal_file = os.path.join(project_path, 'data','anal_signal', 'with_med_FTG/')'''\n",
    "\n",
    "anal_fif = mne.io.read_raw_fif(os.path.join(\n",
    "    project_path,\n",
    "        'data',\n",
    "        'anal_signal',\n",
    "        'with_med_FTG',\n",
    "        'Sub065_AnalFIF.fif'\n",
    "    )\n",
    ")\n",
    "\n",
    "subID = 'Sub005'\n",
    "%matplotlib qt\n",
    "anal_fif.plot(duration = 200)\n",
    "'''cropped_anal_1tp = anal_functions.anal_transitions_1tp(anal_epochs, anal_fif, subID, 20) \n",
    "\n",
    "np.save(str(anal_file) + str(subID)+'sm_analSignal1TP.npy', cropped_anal_1tp)\n",
    "plt.savefig(str(anal_fig) + str(subID)+'sm_analSignal2TP',dpi = 150)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "reload(anal_functions)\n",
    "anal_file = os.path.join(project_path, 'data','anal_signal', 'with_med_FTG/')\n",
    "anal_fig = os.path.join(project_path, 'figures','anal_signal', 'with_med_FTG/')\n",
    "\n",
    "\n",
    "directory = os.path.join(project_path,\n",
    "                         'data',\n",
    "                         'anal_signal',\n",
    "                         'with_med_FTG')  # Update with your directory path\n",
    "\n",
    "# Create a file pattern to match .fif files\n",
    "file_pattern = '*AnalFif_StimNorm.fif'\n",
    "\n",
    "# Get a list of file paths that match the pattern\n",
    "file_list = glob.glob(os.path.join(directory, file_pattern))\n",
    "\n",
    "# Loop through the file list\n",
    "for file_path in file_list:\n",
    "    \n",
    "    file_name = os.path.basename(file_path)\n",
    "    subID = file_name[:6]\n",
    "\n",
    "    anal_fif = mne.io.read_raw_fif(file_path)\n",
    "\n",
    "    cropped_anal_1tp = anal_functions.anal_transitions_1tp(anal_epochs, anal_fif, subID, 30)\n",
    "\n",
    "    np.save(str(anal_file) + str(subID)+'sm_analSignalSubh_On.npy', cropped_anal_1tp)\n",
    "    plt.savefig(str(anal_fig) + str(subID)+'sm_analSignalSubh_On',dpi = 150)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(anal_functions)\n",
    "cropped_anal_2tp = anal_functions.anal_transitions_2tp(anal_epochs, anal_fif, subID, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anal_fig = os.path.join(project_path, 'figures','anal_signal', 'with_med_FTG/')\n",
    "anal_file = os.path.join(project_path, 'data','anal_signal', 'with_med_FTG/')\n",
    "\n",
    "plt.savefig(str(anal_fig) + str(subID)+'sm_analSignal2TP',dpi = 150)\n",
    "np.save(str(anal_file) + str(subID)+'sm_analSignal2TP.npy', cropped_anal_2tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(anal_functions)\n",
    "cropped_anal_1tp = anal_functions.anal_transitions_1tp(anal_epochs, anal_fif, subID, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.savefig(str(anal_fig) + str(subID)+'sm_analSignal1TP',dpi = 150)\n",
    "anal_file = os.path.join(project_path, 'data','anal_signal', 'with_med_FTG/')\n",
    "np.save(str(anal_file) + str(subID)+'sm_analSignal1TP.npy', cropped_anal_1tp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Cropped Analytic Signal and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5000/250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Specify the directory path\n",
    "directory = os.path.join(project_path, 'data', 'anal_signal', 'with_med_FTG')\n",
    "\n",
    "# Find all .npy files in the directory ending with 'analSignal2TP.npy'\n",
    "file_list = [file for file in os.listdir(directory) if file.endswith('Subh_On.npy')]\n",
    "\n",
    "# Create an empty list to store the data arrays\n",
    "data_list = []\n",
    "\n",
    "# Loop through the file list and load the data\n",
    "for file in file_list:\n",
    "    data = np.load(os.path.join(directory, file))\n",
    "\n",
    "    data_list.append(data)  # Select the first 10000 columns\n",
    "\n",
    "# Stack the data arrays along the third axis\n",
    "stacked_data = np.stack(data_list, axis=0)\n",
    "\n",
    "# Calculate the mean and standard error over the 3rd dimension\n",
    "mean_data = np.mean(stacked_data, axis=0)\n",
    "sem_data = np.std(stacked_data, axis=0) / np.sqrt(stacked_data.shape[0])\n",
    "xaxis = np.arange(1,15002)\n",
    "\n",
    "plt.plot(xaxis, mean_data[0,:], label='Spontaneous', color = '#332288')\n",
    "plt.fill_between(xaxis,mean_data[0,:] - sem_data[0,:], mean_data[0,:] + sem_data[0,:], color = '#332288', alpha=0.3)\n",
    "\n",
    "plt.plot(xaxis, mean_data[1,:], label='Entrainment', color = '#CC6677', alpha = 0.3)\n",
    "plt.fill_between(xaxis,mean_data[1,:] - sem_data[1,:], mean_data[1,:] + sem_data[1,:], color = '#CC6677', alpha = 0.2)\n",
    "\n",
    "plt.plot(xaxis, mean_data[2,:], label='Intermediate', color = '#117733')\n",
    "plt.fill_between(xaxis,mean_data[2,:] - sem_data[2,:], mean_data[2,:] + sem_data[2,:], color = '#117733', alpha=0.3)\n",
    "\n",
    "plt.axvline(x=7500, color='grey', linestyle='--', lw = 3, alpha = 0.4, label = 'Entrainment On')\n",
    "\n",
    "\n",
    "plt.ylim(0.6, 1.8)\n",
    "plt.xticks(np.arange(0,17250,2500), labels=np.arange(-30,40,10))\n",
    "plt.xlim(0, 10000)\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Z-scored Smoothed Analytic Signal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_fig = os.path.join(project_path, 'figures', 'anal_signal\\\\')\n",
    "\n",
    "plt.savefig(str(fft_fig)+'AVG_AnalCropped_ENTRAINMENT_ON1',dpi = 300)\n",
    "plt.savefig(str(fft_fig)+'AVG_AnalCropped_ENTRAINMENT_ON1.pdf', format='pdf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make all Signals same Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anal_epochs = pd.read_excel(os.path.join(\n",
    "    project_path,\n",
    "    'data', 'anal_signal',\n",
    "    'Anal_epochs.xlsx'\n",
    "))\n",
    "\n",
    "anal_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(subID) + 'AnalFif_StimNorm.fif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "directory = os.path.join(project_path,\n",
    "                         'data',\n",
    "                         'anal_signal',\n",
    "                         'with_med_FTG//')  # Update with your directory path\n",
    "\n",
    "# Create a file pattern to match .fif files\n",
    "file_pattern = '*AnalFif_StimNorm.fif'\n",
    "\n",
    "# Get a list of file paths that match the pattern\n",
    "file_list = glob.glob(os.path.join(directory, file_pattern))\n",
    "\n",
    "# Loop through the file list\n",
    "for file_path in file_list:\n",
    "    \n",
    "    file_name = os.path.basename(file_path)\n",
    "    subID = file_name[:6]\n",
    "\n",
    "    anal_fif = mne.io.read_raw_fif(file_path, preload=True)\n",
    "\n",
    "    filtered_df = anal_epochs[anal_epochs['Percept_ID'] == subID]\n",
    "    \n",
    "    rec_on = 1\n",
    "    stim_on = filtered_df['Stim_On'].values[0]\n",
    "    subh_on = filtered_df['Subh_On'].values[0]\n",
    "    subh_off = filtered_df['Subh_Off'].values[0]\n",
    "\n",
    "    part1 = anal_fif.copy().crop(tmin=rec_on, tmax = stim_on).get_data()\n",
    "    part2 = anal_fif.copy().crop(tmin=stim_on, tmax = subh_on).get_data()\n",
    "    part3 = anal_fif.copy().crop(tmin=subh_on, tmax = subh_off).get_data()\n",
    "    #part4 = anal_fif.copy().crop(tmin=stim_off, tmax = rec_off).get_data()\n",
    "\n",
    "    np.save(f'{directory}{subID}-Anal_Part1.npy', part1)\n",
    "    np.save(f'{directory}{subID}-Anal_Part2.npy', part2)\n",
    "    np.save(f'{directory}{subID}-Anal_Part3.npy', part3)\n",
    "    #np.save(f'{directory}{subID}-Anal_Part4.npy', part4)\n",
    "\n",
    "'''    #Normalize Stimulation Amplitude and express it between 0-100\n",
    "\n",
    "    data_4th_channel = anal_fif.get_data()[3]\n",
    "\n",
    "    # Normalize the values to range from 0 to 100, ignoring NaN values\n",
    "    min_val = np.nanmin(data_4th_channel)\n",
    "    max_val = np.nanmax(data_4th_channel)\n",
    "    normalized_data = np.where(np.isnan(data_4th_channel), np.nan, ((data_4th_channel - min_val) / (max_val - min_val)) * 100)\n",
    "    \n",
    "    new_ch_name = 'StimNormalized'\n",
    "    new_ch_data = [normalized_data]\n",
    "    new_ch_unit = 'AU'  # Arbitrary unit, adjust as needed\n",
    "\n",
    "    new_ch_info = mne.create_info(ch_names=[new_ch_name], sfreq=anal_fif.info['sfreq'], ch_types=['stim'])\n",
    "    #new_ch_info['ch_names'] = [new_ch_name]\n",
    "\n",
    "    # Create a new RawArray object with the normalized data and info\n",
    "    new_ch_data = mne.io.RawArray(new_ch_data, new_ch_info)\n",
    "\n",
    "    # Add the new channel to the existing data\n",
    "    anal_fif.add_channels([new_ch_data])\n",
    "\n",
    "    # Save the updated FiF file\n",
    "    new_fif_file = str(subID) + 'AnalFif_StimNorm.fif'\n",
    "    anal_fif.save(os.path.join(\n",
    "        directory,\n",
    "        new_fif_file), overwrite=True)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(arrays[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### resample with scipy\n",
    "\n",
    "# Specify the directory path\n",
    "directory = os.path.join(\n",
    "    project_path,\n",
    "    'data', 'anal_signal', 'with_med_FTG'\n",
    ")\n",
    "NEW_N_SAMPLES = 5000\n",
    "\n",
    "# Find all files in the directory ending with 'Anal_Part1.npy'\n",
    "file_list = [file for file in os.listdir(directory) if file.endswith('Anal_Part3.npy')]\n",
    "\n",
    "# Create an empty list to store the arrays\n",
    "arrays = []\n",
    "\n",
    "# Loop through the file list and load the arrays\n",
    "for file in file_list:\n",
    "    array = np.load(os.path.join(directory, file))\n",
    "    arrays.append(array)\n",
    "\n",
    "\n",
    "# Create a new list to store the resized arrays\n",
    "resized_arrays = []\n",
    "\n",
    "# Resize each array to the maximum length\n",
    "for sub_arr in arrays:\n",
    "    # resized_arr = np.resize(arr, (4, 50*250))\n",
    "    resized_arr = np.zeros((sub_arr.shape[0], NEW_N_SAMPLES))\n",
    "    for i_ch, ch in enumerate(sub_arr):\n",
    "        # loop over bandwidths and stim-amps\n",
    "        resized_ch = signal.resample(ch, num=NEW_N_SAMPLES)\n",
    "        resized_arr[i_ch, :] = resized_ch\n",
    "\n",
    "    resized_arrays.append(resized_arr)\n",
    "\n",
    "# Print the resized arrays\n",
    "#for i, arr in enumerate(resized_arrays):\n",
    "#    print(f\"Resized Array {i+1}:\", arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt \n",
    "\n",
    "f, axes = plt.subplots(nrows=2, ncols=4)\n",
    "\n",
    "for i, file in enumerate(file_list):\n",
    "    array = np.load(os.path.join(directory, file))\n",
    "    print(array.shape)\n",
    "    ax = axes.flat[i]\n",
    "    ax.plot(array[1,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3000/250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(nrows=2, ncols=4)\n",
    "\n",
    "for i, arr in enumerate(resized_arrays):\n",
    "    print(arr.shape)\n",
    "    ax = axes.flat[i]\n",
    "    ax.plot(arr[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(\n",
    "    project_path,\n",
    "    'data',\n",
    "    'anal_signal',\n",
    "    'Part3_Resized.npy'),resized_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_list = np.load(os.path.join(\n",
    "    project_path,\n",
    "    'data',\n",
    "    'anal_signal',\n",
    "    'Part3_Resized.npy'))\n",
    "\n",
    "\n",
    "#datall = [dat_ngam, dat_subh, dat_inb, stim] \n",
    "\n",
    "spontan_ch = part_list[:,0,:]\n",
    "subh_ch = part_list[:,1,:]\n",
    "inb_ch = part_list[:,2,:]\n",
    "stim_ch = part_list[:,4,:]\n",
    "\n",
    "mean_spontan = np.mean(spontan_ch, axis = 0)\n",
    "sem_spontan = np.std(spontan_ch, axis=0) / np.sqrt(spontan_ch.shape[0])\n",
    "\n",
    "mean_subh = np.mean(subh_ch, axis = 0)\n",
    "sem_subh = np.std(subh_ch, axis=0) / np.sqrt(subh_ch.shape[0])\n",
    "\n",
    "mean_inb = np.mean(inb_ch, axis = 0)\n",
    "sem_inb = np.std(inb_ch, axis=0) / np.sqrt(inb_ch.shape[0])\n",
    "\n",
    "mean_stim = np.mean(stim_ch, axis = 0)\n",
    "sem_stim = np.std(stim_ch, axis=0) / np.sqrt(stim_ch.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = np.arange(0,part_list.shape[2])\n",
    "\n",
    "plt.plot(xaxis,mean_spontan, label = 'Spontaneous FTG')\n",
    "plt.fill_between(xaxis, mean_spontan - sem_spontan, mean_spontan + sem_spontan, alpha=0.3)\n",
    "\n",
    "plt.plot(xaxis,mean_subh, label = 'Stim-induced FTG')\n",
    "plt.fill_between(xaxis, mean_subh - sem_subh, mean_subh + sem_subh, alpha=0.3)\n",
    "\n",
    "plt.plot(xaxis,mean_inb, label = 'Intermediate Activity')\n",
    "plt.fill_between(xaxis, mean_inb - sem_inb, mean_inb + sem_inb, alpha=0.3)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "mean_vals = {\n",
    "    'mean_spontan': mean_spontan,\n",
    "    'sem_spontan': sem_spontan,\n",
    "    'mean_subh': mean_subh,\n",
    "    'sem_subh': sem_subh,\n",
    "    'mean_inb': mean_inb,\n",
    "    'sem_inb': sem_inb,\n",
    "    'mean_stim': mean_stim,\n",
    "    'sem_stim': sem_stim\n",
    "}\n",
    "\n",
    "# Specify the file path\n",
    "file_path = os.path.join(\n",
    "    project_path,\n",
    "    'data',\n",
    "    'anal_signal',\n",
    ")\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "mean_vals_df = pd.DataFrame.from_dict(mean_vals)\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "mean_vals_df.to_csv(os.path.join(file_path,'Part3_meanvals.csv'), index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grand Plot with all activity over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = os.path.join(\n",
    "    project_path,\n",
    "    'data',\n",
    "    'anal_signal'\n",
    ")\n",
    "\n",
    "df_part1 = pd.read_csv(os.path.join(my_path, 'Part1_meanvals.csv'))\n",
    "df_part2 = pd.read_csv(os.path.join(my_path, 'Part2_meanvals.csv'))\n",
    "df_part3 = pd.read_csv(os.path.join(my_path, 'Part3_meanvals.csv'))\n",
    "\n",
    "allparts_df = pd.concat([df_part1, df_part2, df_part3], axis = 0)\n",
    "\n",
    "print(allparts_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allparts_df.iloc[:5000, allparts_df.columns.get_indexer(['mean_stim', 'sem_stim'])] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig, ax1 = plt.subplots(figsize = (18,6))\n",
    "\n",
    "xaxis = np.arange(0,allparts_df.shape[0])\n",
    "\n",
    "#stim_plot = allparts_df['mean_stim']/2 +0.5\n",
    "\n",
    "stim_plot = allparts_df['mean_stim']\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.plot(xaxis,allparts_df['mean_spontan'], label = 'Spontaneous FTG', color = '#332288')\n",
    "ax1.fill_between(xaxis, allparts_df['mean_spontan'] - allparts_df['sem_spontan'], allparts_df['mean_spontan'] + allparts_df['sem_spontan'], color = '#332288', alpha=0.3)\n",
    "\n",
    "ax1.plot(xaxis,allparts_df['mean_subh'], label = 'Stim-induced FTG', color = '#CC6677')\n",
    "ax1.fill_between(xaxis, allparts_df['mean_subh'] - allparts_df['sem_subh'], allparts_df['mean_subh'] + allparts_df['sem_subh'], color = '#CC6677', alpha=0.3)\n",
    "\n",
    "ax2.plot(xaxis, stim_plot, label = 'Stimulation', alpha = 0.3)\n",
    "ax2.fill_between(xaxis, stim_plot - allparts_df['sem_stim'], stim_plot + allparts_df['sem_stim'], alpha=0.2, color = 'grey')\n",
    "\n",
    "ax1.plot(xaxis, allparts_df['mean_inb'], label = 'Intermediate Activity', color = '#117733')\n",
    "ax1.fill_between(xaxis, allparts_df['mean_inb'] - allparts_df['sem_inb'], allparts_df['mean_inb'] + allparts_df['sem_inb'], color = '#117733', alpha=0.3)\n",
    "\n",
    "\n",
    "plt.axvline(x=5000, color='gray', linestyle='--', linewidth=1.5, label = 'Stim On')\n",
    "plt.axvline(x=15000, color='blue', linestyle='--', linewidth=1.5, label = 'Entrainment On')\n",
    "\n",
    "ax1.set_ylim(0.5,2.5)\n",
    "\n",
    "\n",
    "#ax2.set_yticks(np.arange(0.5,3,0.5), labels = np.arange(0,10,2))\n",
    "\n",
    "plt.xlim(0,18800)\n",
    "ax1.set_ylabel('Z-scored Smoothed Analytic Signal')\n",
    "ax2.set_ylabel('Stimulation Intensity [%]')\n",
    "ax1.set_xlabel('Samples')\n",
    "\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(\n",
    "    project_path,\n",
    "    'figures',\n",
    "    'anal_signal',\n",
    "    'TimeCourse_Gammas'\n",
    "),dpi = 300)\n",
    "\n",
    "plt.savefig(os.path.join(\n",
    "    project_path,\n",
    "    'figures',\n",
    "    'anal_signal',\n",
    "    'TimeCourse_Gammas.pdf'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics in averaged Anal Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_npy = '/Users//barbaramathiopoulou//Desktop//FTG_Figures//Anal_Signal/'\n",
    "\n",
    "part1 = np.load(os.path.join(\n",
    "    path_npy,'Part1_Resized.npy'\n",
    "))\n",
    "\n",
    "part2 = np.load(os.path.join(\n",
    "    path_npy,'Part2_Resized.npy'\n",
    "))\n",
    "\n",
    "part3 = np.load(os.path.join(\n",
    "    path_npy,'Part3_Resized.npy'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1_ftg = np.mean(part1[:,0,:],1)\n",
    "part1_inter = np.mean(part1[:,2,:],1)\n",
    "part1_subh = np.mean(part1[:,1,:],1)\n",
    "\n",
    "part2_ftg = np.mean(part2[:,0,-5000:],1)\n",
    "part2_inter = np.mean(part2[:,2,-5000:],1)\n",
    "part2_subh = np.mean(part2[:,1,-5000:],1)\n",
    "\n",
    "part3_ftg = np.mean(part3[:,0,:],1)\n",
    "part3_inter = np.mean(part3[:,2,:],1)\n",
    "part3_subh = np.mean(part3[:,1,:],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1 = np.mean(part3[:,2,:],1)\n",
    "val2 = np.mean(part3[:,1,:],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, p_value = wilcoxon(val1, val2)\n",
    "print(np.round(p_value, decimals = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT BOXPLOTS\n",
    "%matplotlib qt\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Part 1 subplot\n",
    "axes[0].boxplot([part1_ftg, part1_inter, part1_subh], labels=['FTG', 'Intermediate', 'Entrainment'])\n",
    "axes[0].plot([1, 2, 3], [part1_ftg, part1_inter, part1_subh], 'ko', markersize=8)\n",
    "axes[0].plot([1, 2], [part1_ftg, part1_inter], 'k:', alpha=0.3)\n",
    "axes[0].plot([2, 3], [part1_inter, part1_subh], 'k:', alpha=0.3)\n",
    "axes[0].set_title('DBS Off')\n",
    "axes[0].set_ylabel('Mean Analytic Signal')\n",
    "\n",
    "# Part 2 subplot\n",
    "axes[1].boxplot([part2_ftg, part2_inter, part2_subh], labels=['FTG', 'Intermediate', 'Entrainment'])\n",
    "axes[1].plot([1, 2, 3], [part2_ftg, part2_inter, part2_subh], 'ko', markersize=8)\n",
    "axes[1].plot([1, 2], [part2_ftg, part2_inter], 'k:', alpha=0.3)\n",
    "axes[1].plot([2, 3], [part2_inter, part2_subh], 'k:', alpha=0.3)\n",
    "axes[1].set_title('DBS On-Before Entrainment Onset')\n",
    "\n",
    "# Part 3 subplot\n",
    "axes[2].boxplot([part3_ftg, part3_inter, part3_subh], labels=['FTG', 'Intermediate', 'Entrainment'])\n",
    "axes[2].plot([1, 2, 3], [part3_ftg, part3_inter, part3_subh], 'ko', markersize=8)\n",
    "axes[2].plot([1, 2], [part3_ftg, part3_inter], 'k:', alpha=0.3)\n",
    "axes[2].plot([2, 3], [part3_inter, part3_subh], 'k:', alpha=0.3)\n",
    "axes[2].set_title('DBS On-After Entrainment Onset')\n",
    "\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('AnalSignalMeanBoxplots.pdf')\n",
    "plt.savefig('AnalSignalMeanBoxplots', dpi=200)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switching Stim Off Analytic Signal for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_anal = []\n",
    "\n",
    "ps_path = os.path.join(\n",
    "   project_path,\n",
    "   'data', 'anal_signal', 'switch_off'\n",
    ")\n",
    "\n",
    "for filename in os.listdir(ps_path):\n",
    "   if filename.endswith('SWITCH_OFF.csv'):\n",
    "   #with open(os.path.join(ps_path, filename), 'r') as f: # open in readonly mode\n",
    "      this_df = pd.read_csv(os.path.join(ps_path,filename))\n",
    "      this_stim_anal = this_df['StimOn']\n",
    "\n",
    "      stim_anal.append(this_stim_anal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stim_anal_df = pd.DataFrame(stim_anal)\n",
    "\n",
    "mean_values = all_stim_anal_df.mean(skipna=True)\n",
    "sem_values =  all_stim_anal_df.sem(skipna=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the mean with shaded area for \n",
    "plot_mean = mean_values[:]\n",
    "plot_sem = sem_values[:]\n",
    "plt.plot(plot_mean, color='blue', label = 'Stim-Induced FTG')\n",
    "plt.fill_between(plot_mean.index, plot_mean - plot_sem, plot_mean + plot_sem, color='lightblue')\n",
    "plt.axvline(x = 5000, color = 'grey', ls='--', lw=3, alpha = 0.4, label = 'Stim Off')\n",
    "plt.ylim(0.5,2)\n",
    "plt.xlim(2500,7500)\n",
    "plt.xticks(np.arange(2500,8000,500), labels=np.arange(-10,12,2))\n",
    "plt.legend()\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Z-scored Smoothed Analytic Signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_fig = os.path.join(project_path, 'results\\\\')\n",
    "\n",
    "plt.savefig(str(fft_fig)+'SWITCH_STIM_OFF',dpi = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
